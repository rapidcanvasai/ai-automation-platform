name: AI Test Automation Pipeline

on:
  workflow_dispatch:
    inputs:
      test_description:
        description: 'Test description in plain English'
        required: true
        type: string
      slack_channel:
        description: 'Provide slack channel name(Make sure channel is invited by test-automation-bot)'
        required: false
        type: string
      headless:
        description: 'Run browser in headless mode (true) or show browser window (false)'
        required: false
        type: boolean
        default: true
      enable_slack:
        description: 'Enable Slack notifications'
        required: false
        type: boolean
        default: true

env:
  TEST_DESCRIPTION: ${{ inputs.test_description }}
  OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
  OPENAI_MODEL: "gpt-4o-mini"
  SLACK_CHANNEL: ${{ inputs.slack_channel }}
  SLACK_BOT_TOKEN: ${{ secrets.SLACK_BOT_TOKEN }}
  SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
  ENABLE_SLACK: ${{ inputs.enable_slack }}

jobs:
  create-test-scenario:
    runs-on: ubuntu-latest
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'

    - name: Install backend dependencies
      run: |
        cd backend
        npm ci

    - name: Install Playwright browsers
      run: |
        cd backend
        echo "🔍 Checking Playwright installation..."
        npx playwright --version
        echo "🚀 Installing Chromium browser..."
        npx playwright install chromium
        echo "🔧 Installing system dependencies..."
        npx playwright install-deps chromium
        echo "✅ Playwright installation completed!"
        echo "🔍 Verifying installation..."
        npx playwright install chromium --dry-run

    - name: Build backend
      run: |
        cd backend
        npm run build

    - name: Start backend server
      run: |
        cd backend
        DB_DISABLED=true NODE_ENV=development PORT=3001 npm start &
        echo "Backend server starting..."
        
        # Wait for backend to be ready
        for i in {1..30}; do
          if curl -f http://localhost:3001/health >/dev/null 2>&1; then
            echo "✅ Backend is ready!"
            break
          fi
          echo "Waiting for backend... ($i/30)"
          sleep 2
        done

    - name: Send workflow start notification to Slack
      if: env.ENABLE_SLACK == 'true'
      run: |
        # Set default channel if none provided
        SLACK_CHANNEL_TO_USE="${{ env.SLACK_CHANNEL }}"
        if [ -z "$SLACK_CHANNEL_TO_USE" ]; then
          SLACK_CHANNEL_TO_USE="#test-automation"
          echo "Using default Slack channel: $SLACK_CHANNEL_TO_USE"
        else
          echo "Using provided Slack channel: $SLACK_CHANNEL_TO_USE"
        fi
        
        # Send notification via backend API (reuses existing Slack service)
        curl -X POST -H 'Content-type: application/json' \
        --data '{"messageType":"workflow_start","testDescription":"${{ env.TEST_DESCRIPTION }}","triggeredBy":"${{ github.actor }}","workflowRun":"${{ github.run_id }}","repository":"${{ github.repository }}","jobRunUrl":"${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"}' \
        ${BACKEND_URL:-http://localhost:3001}/api/execution/workflow-notification

    - name: Generate and create complete test scenario
      run: |
        echo "🚀 Generating and creating complete test scenario from: ${{ env.TEST_DESCRIPTION }}"
        echo "Test description length: ${#TEST_DESCRIPTION}"
        
        if [ -z "${{ env.TEST_DESCRIPTION }}" ]; then
          echo "❌ No test description provided"
          echo "Raw env value: '${{ env.TEST_DESCRIPTION }}'"
          exit 1
        fi
        
        echo "✅ Test description provided"
        echo "Creating test-scenarios directory..."
        mkdir -p test-scenarios
        echo "Calling API to parse steps..."
        
        # Create properly escaped JSON payload
        # GitHub Actions converts newlines to spaces, so we need to restore them
        # Use a more robust approach that works across different environments
        echo "🔍 Restoring newlines from GitHub Actions input..."
        echo "Original input: ${{ env.TEST_DESCRIPTION }}"
        
        # Method 1: Try with extended regex (GNU sed)
        TEST_DESC_WITH_NEWLINES=$(echo "${{ env.TEST_DESCRIPTION }}" | sed -E 's/(Open https:|Enter |Click |Verify |Wait )/\n\1/g' 2>/dev/null || echo "${{ env.TEST_DESCRIPTION }}")
        
        # Method 2: If Method 1 failed, try basic regex
        if [ "$TEST_DESC_WITH_NEWLINES" = "${{ env.TEST_DESCRIPTION }}" ]; then
            echo "Trying basic regex approach..."
            TEST_DESC_WITH_NEWLINES=$(echo "${{ env.TEST_DESCRIPTION }}" | sed 's/Open https:/\nOpen https:/g' | sed 's/Enter /\nEnter /g' | sed 's/Click /\nClick /g' | sed 's/Verify /\nVerify /g' | sed 's/Wait /\nWait /g' | sed '1d')
        fi
        
        echo "Restored description:"
        echo "$TEST_DESC_WITH_NEWLINES"
        echo ""
        
        jq -n --arg text "$TEST_DESC_WITH_NEWLINES" '{text: $text}' > /tmp/nlp-payload.json
        
        STEPS_RESPONSE=$(curl -X POST ${BACKEND_URL:-http://localhost:3001}/api/nlp/parse -H "Content-Type: application/json" -d @/tmp/nlp-payload.json -w "\n%{http_code}")
        HTTP_CODE=$(echo "$STEPS_RESPONSE" | tail -n1)
        STEPS_BODY=$(echo "$STEPS_RESPONSE" | sed '$d')
        
        echo "Steps HTTP Code: $HTTP_CODE"
        echo "Steps Response Length: ${#STEPS_BODY}"
        echo "Success: $(echo "$STEPS_BODY" | grep -o '"success":true' || echo 'false')"
        
        # Debug: Check number of steps parsed
        STEPS_COUNT=$(echo "$STEPS_BODY" | jq '.steps | length' 2>/dev/null || echo "0")
        echo "Number of steps parsed: $STEPS_COUNT"
        
        if [ "$STEPS_COUNT" -gt 5 ]; then
            echo "✅ SUCCESS: Multiple steps parsed correctly!"
            echo "First few steps:"
            echo "$STEPS_BODY" | jq '.steps[0:3]'
        else
            echo "❌ ISSUE: Only $STEPS_COUNT step(s) parsed"
            echo "Full response:"
            echo "$STEPS_BODY" | jq '.'
        fi
        
        if [ "$HTTP_CODE" -eq 200 ] || [ "$HTTP_CODE" -eq 201 ]; then
          echo "✅ Test steps generated successfully!"
          echo "Saving NLP parsing response..."
          echo "$STEPS_BODY" > test-scenarios/steps-response-${{ github.run_id }}.json
          echo "Creating payload..."
          echo "$STEPS_BODY" | jq -c '{steps: .steps, language: "typescript"}' > /tmp/steps.json
          echo "Payload created:"
          cat /tmp/steps.json
          echo ""
          
          echo "Calling API to generate code..."
          CODE_RESPONSE=$(curl -X POST ${BACKEND_URL:-http://localhost:3001}/api/nlp/generate-code -H "Content-Type: application/json" -d @/tmp/steps.json -w "\n%{http_code}")
          CODE_HTTP_CODE=$(echo "$CODE_RESPONSE" | tail -n1)
          CODE_BODY=$(echo "$CODE_RESPONSE" | sed '$d')
          
          echo "Code HTTP Code: $CODE_HTTP_CODE"
          echo "Code Response Length: ${#CODE_BODY}"
          echo "Code Success: $(echo "$CODE_BODY" | grep -o '"success":true' || echo 'false')"
          
          if [ "$CODE_HTTP_CODE" -eq 200 ] || [ "$CODE_HTTP_CODE" -eq 201 ]; then
            echo "✅ Test code generated successfully!"
            echo "Creating test scenario files..."
            mkdir -p test-scenarios
            
            echo "Extracting test steps..."
            TEST_STEPS=$(echo "$STEPS_BODY" | jq -r '.steps // .parsedSteps // "No steps generated"' 2>/dev/null || echo "No steps generated - parsing failed")
            
            echo "Creating comprehensive test scenario file..."
            # Create markdown file using echo commands to avoid YAML issues
            echo "# Test Scenario" > test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "Generated on: $(date -u +%Y-%m-%dT%H:%M:%SZ)" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "Triggered by: ${{ github.actor }}" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "Workflow Run: ${{ github.run_id }}" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "## Test Description" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "${{ env.TEST_DESCRIPTION }}" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "## Generated Test Steps" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "\`\`\`json" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "$STEPS_BODY" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "\`\`\`" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "## Generated Test Code Response" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "\`\`\`json" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "$CODE_BODY" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "\`\`\`" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "## Test Steps (Human Readable)" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "$TEST_STEPS" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "## Usage Instructions" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "1. Extract the code from the JSON response above" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "2. Save it as a .js file in your test project" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "3. Run with: npx playwright test your-test-file.js" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            
            echo "Creating raw response file..."
            echo "$CODE_BODY" > test-scenarios/code-response-${{ github.run_id }}.json
            echo "Creating steps file..."
            echo "$TEST_STEPS" > test-scenarios/test-steps-${{ github.run_id }}.txt
            
            echo "✅ Test scenario files created successfully!"
            echo "Files created:"
            ls -la test-scenarios/
            echo "Main file size:"
            wc -c test-scenarios/test-scenario-${{ github.run_id }}.md
          else
            echo "❌ Failed to generate test code"
            echo "Raw code response: $CODE_RESPONSE"
            exit 1
          fi
        else
          echo "❌ Failed to generate test steps"
          echo "Raw steps response: $STEPS_RESPONSE"
          echo "Debug: TEST_DESCRIPTION value: '${{ env.TEST_DESCRIPTION }}'"
          echo "Debug: TEST_DESCRIPTION length: ${#TEST_DESCRIPTION}"
          exit 1
        fi
        
        rm -f /tmp/steps.json /tmp/nlp-payload.json

    - name: Create test in platform and execute
      run: |
        echo "🚀 Creating test in platform and executing..."
        echo "📝 Creating test payload..."
        TEST_NAME="GitHub Action Test - ${{ github.run_id }}"
        
        # Extract steps from the original NLP parsing response (like the frontend does)
        STEPS_DATA=$(cat test-scenarios/steps-response-${{ github.run_id }}.json | jq -c '.steps // []')
        
        echo "🔍 Extracted steps data:"
        echo "$STEPS_DATA" | jq '.'
        echo ""
        
        # Create test payload using jq to properly escape JSON (matching frontend behavior)
        jq -n \
          --arg name "$TEST_NAME" \
          --arg description "${{ env.TEST_DESCRIPTION }}" \
          --argjson steps "$STEPS_DATA" \
          '{
            name: $name,
            description: $description,
            steps: $steps
          }' > /tmp/test-payload.json
        
        echo "Creating test in platform..."
        CREATE_RESPONSE=$(curl -X POST ${BACKEND_URL:-http://localhost:3001}/api/tests -H "Content-Type: application/json" -d @/tmp/test-payload.json -w "\n%{http_code}")
        CREATE_HTTP_CODE=$(echo "$CREATE_RESPONSE" | tail -n1)
        CREATE_BODY=$(echo "$CREATE_RESPONSE" | sed '$d')
        echo "Create Test HTTP Code: $CREATE_HTTP_CODE"
        
        if [ "$CREATE_HTTP_CODE" -eq 201 ]; then
          echo "✅ Test created successfully!"
            TEST_ID=$(echo "$CREATE_BODY" | jq -r '.test.id // "unknown"')
            echo "Test ID: $TEST_ID"
            echo "🔍 Debug: Full create response:"
            echo "$CREATE_BODY" | jq '.'
          echo "🚀 Executing test..."
          
          # Set browser execution mode
          if [ "${{ inputs.headless }}" = "true" ]; then
            HEADLESS_VALUE="true"
            echo "🖥️ Running in HEADLESS mode (browser runs in background)"
          else
            HEADLESS_VALUE="false"
            echo "🖥️ Running in HEADED mode (browser window visible)"
          fi
          
          if [ "${{ env.ENABLE_SLACK }}" = "true" ]; then
            SLACK_VALUE="true"
          else
            SLACK_VALUE="false"
          fi
          
          jq -n \
            --argjson headless "$HEADLESS_VALUE" \
            --argjson enableSlack "$SLACK_VALUE" \
            '{
              headless: $headless,
              slowMoMs: 1000,
              enableSlackNotifications: $enableSlack
            }' > /tmp/exec-payload.json
          
          echo "📋 Execution payload:"
          cat /tmp/exec-payload.json
          echo ""
          
          echo "🔍 Testing execution with test ID: $TEST_ID"
          echo "🔍 Checking if test exists first..."
          curl -X GET ${BACKEND_URL:-http://localhost:3001}/api/tests/$TEST_ID | jq '.test.id // "not found"'
          
          echo "🔍 Debug: Checking Playwright installation in backend..."
          curl -X GET ${BACKEND_URL:-http://localhost:3001}/health | jq '.' || echo "Health check failed"
          
          EXEC_RESPONSE=$(curl -X POST ${BACKEND_URL:-http://localhost:3001}/api/execution/$TEST_ID/run -H "Content-Type: application/json" -d @/tmp/exec-payload.json -w "\n%{http_code}" --max-time 120)
          EXEC_HTTP_CODE=$(echo "$EXEC_RESPONSE" | tail -n1)
          EXEC_BODY=$(echo "$EXEC_RESPONSE" | sed '$d')
          echo "Execution HTTP Code: $EXEC_HTTP_CODE"
          echo "Execution Response: $EXEC_BODY"
          
          if [ "$EXEC_HTTP_CODE" -eq 200 ]; then
            echo "✅ Test executed successfully!"
            echo "Execution Result:"
            echo "$EXEC_BODY" | jq '.'
            EXECUTION_ID=$(echo "$EXEC_BODY" | jq -r '.executionId // "unknown"')
            TEST_STATUS=$(echo "$EXEC_BODY" | jq -r '.status // "unknown"')
            echo "EXECUTION_ID=$EXECUTION_ID" >> $GITHUB_ENV
            echo "TEST_STATUS=$TEST_STATUS" >> $GITHUB_ENV
            echo "TEST_ID=$TEST_ID" >> $GITHUB_ENV
            
            # Check if execution actually completed
            STEPS_EXECUTED=$(echo "$EXEC_BODY" | jq '.result.steps | length' 2>/dev/null || echo "0")
            echo "Steps executed: $STEPS_EXECUTED"
            if [ "$STEPS_EXECUTED" -eq 0 ]; then
              echo "⚠️ WARNING: No steps were executed in the browser."
              echo "This might be due to browser automation issues in Docker environment."
            fi
          elif [ "$EXEC_HTTP_CODE" -eq 404 ]; then
            echo "❌ Test not found (404) - Test ID: $TEST_ID"
            echo "Raw execution response: $EXEC_RESPONSE"
            exit 1
          else
            echo "❌ Test execution failed with HTTP $EXEC_HTTP_CODE"
            echo "Raw execution response: $EXEC_RESPONSE"
            exit 1
          fi
        else
          echo "❌ Failed to create test"
          echo "Raw create response: $CREATE_RESPONSE"
          exit 1
        fi
        
        # Cleanup
        rm -f /tmp/test-payload.json /tmp/exec-payload.json


    - name: Verify test execution results
      run: |
        echo "📊 Verifying test execution results..."
        if [ -n "${{ env.EXECUTION_ID }}" ]; then
          echo "✅ Test executed in platform successfully!"
          echo "Execution ID: ${{ env.EXECUTION_ID }}"
          echo "Test Status: ${{ env.TEST_STATUS }}"
          echo "Test ID: ${{ env.TEST_ID }}"
          
          # Get detailed execution results
          echo "📋 Getting detailed execution results..."
          DETAILED_RESULTS=$(curl -X GET "${BACKEND_URL:-http://localhost:3001}/api/execution/${{ env.EXECUTION_ID }}/results" | jq '.')
          echo "Detailed Results:"
          echo "$DETAILED_RESULTS" | jq '.'
          
          STEPS_EXECUTED=$(echo "$DETAILED_RESULTS" | jq '.execution.result.steps | length')
          echo "Steps executed: $STEPS_EXECUTED"
          
          if [ "$STEPS_EXECUTED" -gt 0 ]; then
            echo "🎉 SUCCESS: Browser execution completed! Steps were executed."
            echo "Step details:"
            echo "$DETAILED_RESULTS" | jq '.execution.result.steps[] | {step: .step, action: .action, target: .target, status: .status, error: .error}'
          else
            echo "⚠️ WARNING: No steps were executed in the browser."
          fi
        else
          echo "❌ No execution ID found - test may not have been executed"
        fi

    - name: Upload test scenarios
      uses: actions/upload-artifact@v4
      with:
        name: test-scenarios-${{ github.run_id }}
        path: test-scenarios/
        retention-days: 30

    - name: Upload test results
      uses: actions/upload-artifact@v4
      with:
        name: test-results-${{ github.run_id }}
        path: backend/test-results/
        retention-days: 30

    - name: Send workflow completion notification to Slack
      if: env.ENABLE_SLACK == 'true'
      run: |
        # Set default channel if none provided
        SLACK_CHANNEL_TO_USE="${{ env.SLACK_CHANNEL }}"
        if [ -z "$SLACK_CHANNEL_TO_USE" ]; then
          SLACK_CHANNEL_TO_USE="#test-automation"
          echo "Using default Slack channel: $SLACK_CHANNEL_TO_USE"
        else
          echo "Using provided Slack channel: $SLACK_CHANNEL_TO_USE"
        fi
        
        if [ -n "${{ env.TEST_STATUS }}" ]; then
          STATUS_EMOJI="✅"
          STATUS_TEXT="SUCCESS"
          if [ "${{ env.TEST_STATUS }}" != "passed" ]; then
            STATUS_EMOJI="❌"
            STATUS_TEXT="FAILED"
          fi
          curl -X POST -H 'Content-type: application/json' \
          --data '{"messageType":"workflow_complete","testDescription":"${{ env.TEST_DESCRIPTION }}","triggeredBy":"${{ github.actor }}","workflowRun":"${{ github.run_id }}","repository":"${{ github.repository }}","testId":"${{ env.TEST_ID }}","executionId":"${{ env.EXECUTION_ID }}","testStatus":"${{ env.TEST_STATUS }}","jobRunUrl":"${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"}' \
          ${BACKEND_URL:-http://localhost:3001}/api/execution/workflow-notification
        else
          curl -X POST -H 'Content-type: application/json' \
          --data '{"messageType":"workflow_complete","testDescription":"${{ env.TEST_DESCRIPTION }}","triggeredBy":"${{ github.actor }}","workflowRun":"${{ github.run_id }}","repository":"${{ github.repository }}","testStatus":"generated","jobRunUrl":"${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}"}' \
          ${BACKEND_URL:-http://localhost:3001}/api/execution/workflow-notification
        fi

    - name: Comment on workflow
      run: |
        echo "✅ AI Test Automation Pipeline completed successfully!"
        echo ""
        echo "📊 Pipeline Summary:"
        echo "   • Natural language processing: ✅"
        echo "   • Test code generation: ✅"
        echo "   • Test creation in platform: ✅"
        echo "   • Test execution: ✅"
        echo "   • Slack notifications: ✅"
        echo ""
        echo "📁 Files uploaded as artifacts:"
        echo "   - test-scenario-${{ github.run_id }}.md (comprehensive report)"
        echo "   - code-response-${{ github.run_id }}.json (raw code response)"
        echo "   - test-steps-${{ github.run_id }}.txt (human readable steps)"
          echo "   - test-results-${{ github.run_id }} (test execution results)"
          echo "   - generated-test-${{ github.run_id }}.js (executable test file)"
        echo ""
        echo "🎯 Next steps:"
        echo "   1. Download the artifacts from this workflow run"
          echo "   2. ✅ Tests were executed automatically!"
          echo "   3. Check test-results artifact for screenshots/videos"
          echo "   4. Use generated-test-${{ github.run_id }}.js for future runs"
        echo "   5. Check Slack for detailed execution notifications"
        echo ""
        echo "🔗 Platform Integration:"
        echo "   • Test created in platform with ID: ${{ env.TEST_ID }}"
        echo "   • Execution ID: ${{ env.EXECUTION_ID }}"
        echo "   • Status: ${{ env.TEST_STATUS }}"