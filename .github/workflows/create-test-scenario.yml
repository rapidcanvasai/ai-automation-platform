name: AI Test Automation Pipeline

on:
  workflow_dispatch:
    inputs:
      test_description:
        description: 'Test description in plain English. For supported commands, see: https://rapidcanvas.atlassian.net/wiki/spaces/RAPIDCANVA/pages/887554049/Test+Automation+Platform+-+Supported+Commands+Documentation'
        required: true
        type: string
      slack_channel:
        description: 'Provide slack channel name(Make sure bot - test-automation-platform is added to mentioned slack channel)'
        required: false
        type: string
      slack_channel_id:
        description: 'Provide slack channel ID (e.g., C09F5F2MH8D). You can find this by right-clicking on the channel name in Slack and selecting "Copy link"'
        required: false
        type: string
      headless:
        description: 'Run browser in headless mode (true) or show browser window (false) - GitHub Actions default is headless'
        required: false
        type: boolean
        default: true
      enable_slack:
        description: 'Enable Slack notifications'
        required: false
        type: boolean
        default: true
      slack_notify_only_failures:
        description: 'Send Slack notifications only for failed tests (only applies if enable_slack is true)'
        required: false
        type: boolean
        default: false
      slack_mention:
        description: 'Slack user to mention in thread replies (e.g., "Leonardo", "@Bruno", or user ID like "U123456")'
        required: false
        type: string
      dataapp_name:
        description: 'DataApp name to display in Slack notifications (only shown for failed tests)'
        required: false
        type: string
      tenant_name:
        description: 'Tenant name to display in Slack notifications (only shown for failed tests)'
        required: false
        type: string

env:
  TEST_DESCRIPTION: ${{ inputs.test_description }}
  OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
  OPENAI_MODEL: "gpt-4o-mini"
  SLACK_CHANNEL: ${{ inputs.slack_channel }}
  SLACK_CHANNEL_ID: ${{ inputs.slack_channel_id }}
  SLACK_BOT_TOKEN: ${{ secrets.SLACK_BOT_TOKEN }}
  SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
  ENABLE_SLACK: ${{ inputs.enable_slack }}
  SLACK_NOTIFY_ONLY_FAILURES: ${{ inputs.slack_notify_only_failures }}
  SLACK_MENTION: ${{ inputs.slack_mention }}
  DATAAPP_NAME: ${{ inputs.dataapp_name }}
  TENANT_NAME: ${{ inputs.tenant_name }}

jobs:
  create-test-scenario:
    runs-on: ubuntu-latest
    
    steps:
    - name: üìö Documentation Link
      run: |
        echo "## üìö Test Automation Documentation" >> $GITHUB_STEP_SUMMARY
        echo "**Supported Commands**: [View Documentation](https://rapidcanvas.atlassian.net/wiki/spaces/RAPIDCANVA/pages/887554049/Test+Automation+Platform+-+Supported+Commands+Documentation)" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "This documentation contains all supported commands and syntax for writing test descriptions." >> $GITHUB_STEP_SUMMARY

    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'

    - name: Install backend dependencies
      run: |
        cd backend
        npm ci

    - name: Install Playwright browsers
      run: |
        cd backend
        echo "üîç Checking Playwright installation..."
        npx playwright --version
        echo "üöÄ Installing Chromium browser..."
        npx playwright install chromium
        echo "üîß Installing system dependencies..."
        npx playwright install-deps chromium
        echo "‚úÖ Playwright installation completed!"
        echo "üîç Verifying installation..."
        npx playwright install chromium --dry-run

    - name: Build backend
      run: |
        cd backend
        npm run build

    - name: Start backend server
      run: |
        cd backend
        DB_DISABLED=true NODE_ENV=development PORT=3001 SLACK_CHANNEL_ID=${{ env.SLACK_CHANNEL_ID }} npm start &
        echo "Backend server starting..."
        
        # Wait for backend to be ready
        for i in {1..30}; do
          if curl -f http://localhost:3001/health >/dev/null 2>&1; then
            echo "‚úÖ Backend is ready!"
            break
          fi
          echo "Waiting for backend... ($i/30)"
          sleep 2
        done

    - name: Generate and create complete test scenario
      run: |
        echo "üöÄ Generating and creating complete test scenario from: ${{ env.TEST_DESCRIPTION }}"
        echo "Test description length: ${#TEST_DESCRIPTION}"
        
        if [ -z "${{ env.TEST_DESCRIPTION }}" ]; then
          echo "‚ùå No test description provided"
          echo "Raw env value: '${{ env.TEST_DESCRIPTION }}'"
          exit 1
        fi
        
        echo "‚úÖ Test description provided"
        echo "Creating test-scenarios directory..."
        mkdir -p test-scenarios
        echo "Calling API to parse steps..."
        
        # Create properly escaped JSON payload
        # GitHub Actions converts newlines to spaces, so we need to restore them
        # The web interface sends text with actual \n characters, so we need to match that
        echo "üîç Restoring newlines to match web interface format..."
        echo "Original input: ${{ env.TEST_DESCRIPTION }}"
        
        # Convert spaces back to newlines for action keywords (same as web interface)
        # The NLP service splits on newlines, so we need to restore them from spaces
        # Strategy: Use perl to split on action keywords that appear after word boundaries
        
        # Start with the original description
        TEST_DESC_WITH_NEWLINES="${{ env.TEST_DESCRIPTION }}"
        
        # Normalize multiple spaces to single space first
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/\s+/ /g')
        
        # CRITICAL: Add spaces before action keywords when they're concatenated
        # This handles cases like "Wait 2secEnter" -> "Wait 2sec Enter"
        # Pattern: lowercase/digit followed by uppercase action keyword
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/([a-z0-9])(Wait \d+sec)/$1 $2/gi')
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/([a-z0-9])(Enter )/$1 $2/gi')
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/([a-z0-9])(Click )/$1 $2/gi')
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/([a-z0-9])(Verify )/$1 $2/gi')
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/([a-z0-9])(Open https:)/$1 $2/gi')
        
        # Handle concatenated patterns like "Wait 2secEnter" -> "Wait 2sec Enter"
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/(Wait \d+sec)(Enter )/$1 $2/gi')
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/(Wait \d+sec)(Click )/$1 $2/gi')
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/(Wait \d+sec)(Verify )/$1 $2/gi')
        
        # Handle "Verify XEnter" -> "Verify X Enter"
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/(Verify [^E]+(?:with AI)?)(Enter )/$1 $2/gi')
        
        # Handle Open URLs first (most specific pattern)
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/\s+Open https:/\nOpen https:/g')
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/^Open https:/Open https:/g')
        
        # CRITICAL: Handle combined Wait patterns BEFORE general Wait splitting
        # Handle "Wait Xsec Enter Y" pattern - split into two steps
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/(Wait \d+sec)\s+Enter ([A-Z])/$1\nEnter $2/gi')
        
        # Handle "Wait Xsec Verify Y" pattern - split into two steps  
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/(Wait \d+sec)\s+Verify ([A-Za-z])/$1\nVerify $2/gi')
        
        # Handle Wait - pattern: "Wait Xsec" (now with spaces normalized)
        # This comes AFTER the combined patterns above
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/\s+Wait (\d+sec)/\nWait $1/g')
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/^Wait (\d+sec)/Wait $1/g')
        
        # Handle "Verify X Enter Y" pattern explicitly FIRST - split into two steps
        # This must come before general Verify splitting to catch combined steps
        # Pattern: "Verify ... Enter Which..." or "Verify ... Enter Show..."
        # Match "Verify" followed by text (including "E" characters) until " Enter " (with spaces)
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/(Verify .+?)\s+Enter ([A-Z])/$1\nEnter $2/gi')
        
        # Handle "Verify X Verify Y" pattern - split consecutive Verify statements
        # Pattern: "Verify ... Verify New..." or "Verify ... Verify Yale..."
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/(Verify [^V]+(?:with AI)?)\s+Verify ([A-Z])/$1\nVerify $2/gi')
        
        # Handle Verify - split on " Verify X" or "Verify X" at start
        # Accept both capital and lowercase first letters (e.g., "Verify no error...")
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/\s+Verify ([A-Za-z])/\nVerify $1/g')
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/^Verify ([A-Za-z])/Verify $1/g')
        
        # Handle Enter - split on " Enter X in Y" or "Enter X in Y" at start
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/\s+Enter ([^C][^l][^i][^c][^k][^E][^n][^t][^e][^r]+) in /\nEnter $1 in /g')
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/^Enter ([^C][^l][^i][^c][^k][^E][^n][^t][^e][^r]+) in /Enter $1 in /g')
        
        # Handle "Enter X" without "in" (for AI input fields starting with capital letter)
        # Pattern: "Enter Which models..." or "Enter Show me..." etc.
        # Must not be followed immediately by another action keyword
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/\s+Enter ([A-Z][^V][^e][^r][^i][^f][^y][^C][^l][^i][^c][^k]+)(?=\s+(?:Click|Verify|Wait|Enter|Open|Set|If|Else|End|Upload|$))/\nEnter $1/g')
        
        # Handle If statements - split before "If" when it appears after a word
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/([a-z0-9\s])(If\s+)/$1\n$2/gi')
        # Handle "If(" pattern
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/([a-z0-9\s])(If\()/$1\n$2/gi')
        
        # Handle End if / Endif statements (case insensitive)
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/([a-z0-9\s])(End\s+if)/$1\n$2/gi')
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/([a-z0-9\s])(Endif)/$1\n$2/gi')
        
        # Handle Set statements - pattern: "Set variable="
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/([a-z0-9\s])(Set\s+[a-zA-Z_][a-zA-Z0-9_]*=)/$1\n$2/gi')
        
        # Handle Else statements
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/([a-z0-9\s])(Else\s+)/$1\n$2/gi')
        
        # Handle Upload - pattern: "Upload filename.csv to target"
        # Important: "Upload X.csv to Click to select" should stay as ONE line
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/([a-z0-9\s])(Upload\s+[A-Za-z0-9_][^\s]*\.csv)/$1\n$2/gi')
        
        # Merge back: "Upload X.csv\nto" should be "Upload X.csv to" (one step)
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/(Upload\s+[^\s]*\.csv)\nto/$1 to/gi')
        
        # Handle Click - split on " Click on X" or "Click on X" at start
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/\s+Click on /\nClick on /g')
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/^Click on /Click on /g')
        # Handle concatenated: "XClick on X" -> "X\nClick on X"
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/([a-z0-9])(Click on )/$1\n$2/gi')
        
        # Split on " Click X" (where X starts with capital) or "Click X" at start
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/\s+Click ([A-Z])/\nClick $1/g')
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/^Click ([A-Z])/Click $1/g')
        # Handle concatenated: "XClick X" -> "X\nClick X"
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/([a-z0-9])(Click [A-Z])/$1\n$2/gi')
        
        # Fix: merge back "Click to" (part of upload target, not a new action)
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/\nClick\s+to/ Click to/gi')
        
        # Handle "then" clauses - split action after "then"
        # Pattern: "then action" where action is Click, Enter, Wait, Verify, Set, etc.
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/\s+then\s+(Click|Enter|Wait|Verify|Set|Open|If|Else|End|Upload)/\nthen $1/gi')
        
        # Fix bad splits using perl (works on both BSD and GNU sed environments)
        # Merge "Verify\nUpload" back to "Verify Upload" (Upload is target, not new action)
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/\nVerify\nUpload/ Verify Upload/g')
        
        # Fix bad splits: merge "Upload X.csv\nto" back to "Upload X.csv to" (one step)
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/(Upload [^ ]*\.csv)\nto/$1 to/g')
        
        # Fix bad splits: merge "Upload X.csv\nto Click" back to "Upload X.csv to Click"
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/(Upload [^ ]*\.csv)\nto Click/$1 to Click/g')
        
        # Clean up: Remove any double newlines that might have been created
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/\n\n+/\n/g')
        
        # Clean up: Remove leading/trailing whitespace from each line
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | perl -pe 's/^\s+//; s/\s+$//')
        
        echo "Restored description with newlines:"
        echo "$TEST_DESC_WITH_NEWLINES"
        echo ""
        
        jq -n --arg text "$TEST_DESC_WITH_NEWLINES" '{text: $text}' > /tmp/nlp-payload.json
        
        STEPS_RESPONSE=$(curl -X POST ${BACKEND_URL:-http://localhost:3001}/api/nlp/parse -H "Content-Type: application/json" -d @/tmp/nlp-payload.json -w "\n%{http_code}")
        HTTP_CODE=$(echo "$STEPS_RESPONSE" | tail -n1)
        STEPS_BODY=$(echo "$STEPS_RESPONSE" | sed '$d')
        
        echo "Steps HTTP Code: $HTTP_CODE"
        echo "Steps Response Length: ${#STEPS_BODY}"
        echo "Success: $(echo "$STEPS_BODY" | grep -o '"success":true' || echo 'false')"
        
        # Debug: Check number of steps parsed
        STEPS_COUNT=$(echo "$STEPS_BODY" | jq '.steps | length' 2>/dev/null || echo "0")
        echo "Number of steps parsed: $STEPS_COUNT"
        
        if [ "$STEPS_COUNT" -gt 5 ]; then
            echo "‚úÖ SUCCESS: Multiple steps parsed correctly!"
            echo "First few steps:"
            echo "$STEPS_BODY" | jq '.steps[0:3]'
        else
            echo "‚ùå ISSUE: Only $STEPS_COUNT step(s) parsed"
            echo "Full response:"
            echo "$STEPS_BODY" | jq '.'
        fi
        
        if [ "$HTTP_CODE" -eq 200 ] || [ "$HTTP_CODE" -eq 201 ]; then
          echo "‚úÖ Test steps generated successfully!"
          echo "Saving NLP parsing response..."
          echo "$STEPS_BODY" > test-scenarios/steps-response-${{ github.run_id }}.json
          echo "Creating payload..."
          echo "$STEPS_BODY" | jq -c '{steps: .steps, language: "typescript"}' > /tmp/steps.json
          echo "Payload created:"
          cat /tmp/steps.json
          echo ""
          
          echo "Calling API to generate code..."
          CODE_RESPONSE=$(curl -X POST ${BACKEND_URL:-http://localhost:3001}/api/nlp/generate-code -H "Content-Type: application/json" -d @/tmp/steps.json -w "\n%{http_code}")
          CODE_HTTP_CODE=$(echo "$CODE_RESPONSE" | tail -n1)
          CODE_BODY=$(echo "$CODE_RESPONSE" | sed '$d')
          
          echo "Code HTTP Code: $CODE_HTTP_CODE"
          echo "Code Response Length: ${#CODE_BODY}"
          echo "Code Success: $(echo "$CODE_BODY" | grep -o '"success":true' || echo 'false')"
          
          if [ "$CODE_HTTP_CODE" -eq 200 ] || [ "$CODE_HTTP_CODE" -eq 201 ]; then
            echo "‚úÖ Test code generated successfully!"
            echo "Creating test scenario files..."
            mkdir -p test-scenarios
            
            echo "Extracting test steps..."
            TEST_STEPS=$(echo "$STEPS_BODY" | jq -r '.steps // .parsedSteps // "No steps generated"' 2>/dev/null || echo "No steps generated - parsing failed")
            
            echo "Creating comprehensive test scenario file..."
            # Create markdown file using echo commands to avoid YAML issues
            echo "# Test Scenario" > test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "Generated on: $(date -u +%Y-%m-%dT%H:%M:%SZ)" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "Triggered by: ${{ github.actor }}" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "Workflow Run: ${{ github.run_id }}" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "## Test Description" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "${{ env.TEST_DESCRIPTION }}" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "## Generated Test Steps" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "\`\`\`json" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "$STEPS_BODY" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "\`\`\`" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "## Generated Test Code Response" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "\`\`\`json" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "$CODE_BODY" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "\`\`\`" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "## Test Steps (Human Readable)" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "$TEST_STEPS" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "## Usage Instructions" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "1. Extract the code from the JSON response above" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "2. Save it as a .js file in your test project" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "3. Run with: npx playwright test your-test-file.js" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            
            echo "Creating raw response file..."
            echo "$CODE_BODY" > test-scenarios/code-response-${{ github.run_id }}.json
            echo "Creating steps file..."
            echo "$TEST_STEPS" > test-scenarios/test-steps-${{ github.run_id }}.txt
            
            echo "‚úÖ Test scenario files created successfully!"
            echo "Files created:"
            ls -la test-scenarios/
            echo "Main file size:"
            wc -c test-scenarios/test-scenario-${{ github.run_id }}.md
          else
            echo "‚ùå Failed to generate test code"
            echo "Raw code response: $CODE_RESPONSE"
            exit 1
          fi
        else
          echo "‚ùå Failed to generate test steps"
          echo "Raw steps response: $STEPS_RESPONSE"
          echo "Debug: TEST_DESCRIPTION value: '${{ env.TEST_DESCRIPTION }}'"
          echo "Debug: TEST_DESCRIPTION length: ${#TEST_DESCRIPTION}"
          exit 1
        fi
        
        rm -f /tmp/steps.json /tmp/nlp-payload.json

    - name: Create test in platform and execute
      run: |
        echo "üöÄ Creating test in platform and executing..."
        echo "üìù Creating test payload..."
        TEST_NAME="GitHub Action Test - ${{ github.run_id }}"
        
        # Extract steps from the original NLP parsing response (like the frontend does)
        STEPS_DATA=$(cat test-scenarios/steps-response-${{ github.run_id }}.json | jq -c '.steps // []')
        
        echo "üîç Extracted steps data:"
        echo "$STEPS_DATA" | jq '.'
        echo ""
        
        # Prepare slack notify only failures flag
        if [ "${{ env.SLACK_NOTIFY_ONLY_FAILURES }}" = "true" ]; then
          SLACK_NOTIFY_ONLY_FAILURES_VALUE="true"
        else
          SLACK_NOTIFY_ONLY_FAILURES_VALUE="false"
        fi
        
        # Create test payload using jq to properly escape JSON (matching frontend behavior)
        # Include slackMention if provided
        if [ -n "${{ env.SLACK_MENTION }}" ]; then
          jq -n \
            --arg name "$TEST_NAME" \
            --arg description "${{ env.TEST_DESCRIPTION }}" \
            --argjson steps "$STEPS_DATA" \
            --arg workflowRunUrl "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}" \
            --argjson slackNotifyOnlyFailures "$SLACK_NOTIFY_ONLY_FAILURES_VALUE" \
            --arg slackMention "${{ env.SLACK_MENTION }}" \
            '{
              name: $name,
              description: $description,
              steps: $steps,
              workflowRunUrl: $workflowRunUrl,
              slackNotifyOnlyFailures: $slackNotifyOnlyFailures,
              slackMention: $slackMention
            }' > /tmp/test-payload.json
        else
          jq -n \
            --arg name "$TEST_NAME" \
            --arg description "${{ env.TEST_DESCRIPTION }}" \
            --argjson steps "$STEPS_DATA" \
            --arg workflowRunUrl "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}" \
            --argjson slackNotifyOnlyFailures "$SLACK_NOTIFY_ONLY_FAILURES_VALUE" \
            '{
              name: $name,
              description: $description,
              steps: $steps,
              workflowRunUrl: $workflowRunUrl,
              slackNotifyOnlyFailures: $slackNotifyOnlyFailures
            }' > /tmp/test-payload.json
        fi
        
        echo "Creating test in platform..."
        CREATE_RESPONSE=$(curl -X POST ${BACKEND_URL:-http://localhost:3001}/api/tests -H "Content-Type: application/json" -d @/tmp/test-payload.json -w "\n%{http_code}")
        CREATE_HTTP_CODE=$(echo "$CREATE_RESPONSE" | tail -n1)
        CREATE_BODY=$(echo "$CREATE_RESPONSE" | sed '$d')
        echo "Create Test HTTP Code: $CREATE_HTTP_CODE"
        
        if [ "$CREATE_HTTP_CODE" -eq 201 ]; then
          echo "‚úÖ Test created successfully!"
            TEST_ID=$(echo "$CREATE_BODY" | jq -r '.test.id // "unknown"')
            echo "Test ID: $TEST_ID"
            echo "üîç Debug: Full create response:"
            echo "$CREATE_BODY" | jq '.'
          echo "üöÄ Executing test..."
          
          # Set browser execution mode for GitHub Actions
          # GitHub Actions default is headless: true (no GUI available)
          if [ "${{ inputs.headless }}" = "true" ]; then
            HEADLESS_VALUE="true"
            echo "üñ•Ô∏è Running in HEADLESS mode (GitHub Actions - no GUI available)"
          else
            HEADLESS_VALUE="false"
            echo "üñ•Ô∏è Running in HEADED mode (browser window visible) - not recommended for GitHub Actions"
          fi
          
          if [ "${{ env.ENABLE_SLACK }}" = "true" ]; then
            SLACK_VALUE="true"
          else
            SLACK_VALUE="false"
          fi
          
          if [ "${{ env.SLACK_NOTIFY_ONLY_FAILURES }}" = "true" ]; then
            SLACK_NOTIFY_ONLY_FAILURES_VALUE="true"
          else
            SLACK_NOTIFY_ONLY_FAILURES_VALUE="false"
          fi
          
          # Match web interface execution parameters exactly
          jq -n \
            --argjson headless "$HEADLESS_VALUE" \
            --argjson enableSlack "$SLACK_VALUE" \
            --argjson slackNotifyOnlyFailures "$SLACK_NOTIFY_ONLY_FAILURES_VALUE" \
            '{
              headless: $headless,
              slowMoMs: 1000,
              enableSlackNotifications: $enableSlack,
              slackNotifyOnlyFailures: $slackNotifyOnlyFailures
            }' > /tmp/exec-payload.json
          
          echo "üìã Execution payload:"
          cat /tmp/exec-payload.json
          echo ""
          
          echo "üîç Testing execution with test ID: $TEST_ID"
          echo "üîç Checking if test exists first..."
          curl -X GET ${BACKEND_URL:-http://localhost:3001}/api/tests/$TEST_ID | jq '.test.id // "not found"'
          
          echo "üîç Debug: Checking Playwright installation in backend..."
          curl -X GET ${BACKEND_URL:-http://localhost:3001}/health | jq '.' || echo "Health check failed"
          
          # Verify backend is still running before execution
          echo "üîç Verifying backend is still running..."
          if ! curl -f ${BACKEND_URL:-http://localhost:3001}/health >/dev/null 2>&1; then
            echo "‚ùå Backend server is not responding. It may have crashed."
            echo "Attempting to check backend process..."
            ps aux | grep -E "node.*backend|npm.*start" | grep -v grep || echo "No backend process found"
            exit 1
          fi
          echo "‚úÖ Backend is running"
          
          echo "üöÄ Executing test..."
          # Increased timeout to 45 minutes (2700 seconds) to accommodate tests with multiple long waits
          # Test includes multiple "Wait 100sec" steps which can easily exceed 10 minutes
          # Use --show-error to show error messages, and capture both stdout and stderr
          # Don't use --fail so we can capture the response even on errors
          EXEC_RESPONSE=$(curl -X POST ${BACKEND_URL:-http://localhost:3001}/api/execution/$TEST_ID/run \
            -H "Content-Type: application/json" \
            -d @/tmp/exec-payload.json \
            -w "\n%{http_code}" \
            --max-time 2700 \
            --show-error \
            2>&1) || EXEC_CURL_EXIT=$?
          
          EXEC_HTTP_CODE=$(echo "$EXEC_RESPONSE" | tail -n1)
          EXEC_BODY=$(echo "$EXEC_RESPONSE" | sed '$d')
          
          # Check if curl failed due to connection issues
          if [ -n "$EXEC_CURL_EXIT" ] && [ "$EXEC_CURL_EXIT" -ne 0 ]; then
            echo "‚ö†Ô∏è Curl command failed with exit code: $EXEC_CURL_EXIT"
            echo "This might indicate the server crashed or connection was lost."
            echo "Checking if backend is still running..."
            if ! curl -f ${BACKEND_URL:-http://localhost:3001}/health >/dev/null 2>&1; then
              echo "‚ùå Backend server crashed during execution"
              echo "This is likely due to browser automation issues in Docker environment."
              echo "Full curl output:"
              echo "$EXEC_RESPONSE"
              # Don't exit 1 here - allow workflow to continue and report the issue
              echo "‚ö†Ô∏è Continuing workflow despite execution failure..."
            else
              echo "Backend is still running, but execution request failed"
              echo "Full curl output:"
              echo "$EXEC_RESPONSE"
            fi
          fi
          
          echo "Execution HTTP Code: $EXEC_HTTP_CODE"
          echo "Execution Response (first 500 chars):"
          echo "$EXEC_BODY" | head -c 500
          echo ""
          
          # Validate JSON before parsing
          if ! echo "$EXEC_BODY" | jq empty 2>/dev/null; then
            echo "‚ö†Ô∏è Warning: Response is not valid JSON. Raw response:"
            echo "$EXEC_BODY"
          fi
          
          # Try to parse HTTP code - if it's not a number, curl likely failed
          if ! echo "$EXEC_HTTP_CODE" | grep -qE '^[0-9]+$'; then
            echo "‚ö†Ô∏è Could not parse HTTP code. Response may be empty or malformed."
            echo "This usually means the server crashed or connection was lost."
            echo "Attempting to check execution status via alternative method..."
            
            # Try to get the latest execution for this test
            LATEST_EXEC=$(curl -s ${BACKEND_URL:-http://localhost:3001}/api/execution?testId=$TEST_ID | jq '.executions[0] // empty' 2>/dev/null)
            if [ -n "$LATEST_EXEC" ] && [ "$LATEST_EXEC" != "null" ] && [ "$LATEST_EXEC" != "" ]; then
              echo "Found execution record:"
              echo "$LATEST_EXEC" | jq '.'
              EXECUTION_ID=$(echo "$LATEST_EXEC" | jq -r '.id // "unknown"')
              TEST_STATUS=$(echo "$LATEST_EXEC" | jq -r '.result.status // "unknown"')
              echo "EXECUTION_ID=$EXECUTION_ID" >> $GITHUB_ENV
              echo "TEST_STATUS=$TEST_STATUS" >> $GITHUB_ENV
              echo "TEST_ID=$TEST_ID" >> $GITHUB_ENV
              echo "‚ö†Ô∏è Execution may have started but connection was lost. Check execution ID: $EXECUTION_ID"
            else
              echo "‚ùå No execution record found. Test execution likely failed."
              echo "This is common in Docker environments where browser automation may not work."
              echo "TEST_STATUS=failed" >> $GITHUB_ENV
              echo "TEST_ID=$TEST_ID" >> $GITHUB_ENV
            fi
          elif [ "$EXEC_HTTP_CODE" -eq 200 ]; then
            echo "‚úÖ Test executed successfully!"
            echo "Execution Result:"
            # Validate JSON before parsing
            if echo "$EXEC_BODY" | jq empty >/dev/null 2>&1; then
              echo "$EXEC_BODY" | jq '.'
              EXECUTION_ID=$(echo "$EXEC_BODY" | jq -r '.executionId // "unknown"')
              TEST_STATUS=$(echo "$EXEC_BODY" | jq -r '.status // "unknown"')
            else
              echo "‚ö†Ô∏è Warning: Response is not valid JSON. Attempting to extract data..."
              echo "Raw response (first 1000 chars):"
              echo "$EXEC_BODY" | head -c 1000
              echo ""
              # Try to extract execution ID and status using grep/sed as fallback
              EXECUTION_ID=$(echo "$EXEC_BODY" | grep -o '"executionId"[[:space:]]*:[[:space:]]*"[^"]*"' | head -1 | sed 's/.*"executionId"[[:space:]]*:[[:space:]]*"\([^"]*\)".*/\1/' || echo "unknown")
              TEST_STATUS=$(echo "$EXEC_BODY" | grep -o '"status"[[:space:]]*:[[:space:]]*"[^"]*"' | head -1 | sed 's/.*"status"[[:space:]]*:[[:space:]]*"\([^"]*\)".*/\1/' || echo "unknown")
            fi
            echo "EXECUTION_ID=$EXECUTION_ID" >> $GITHUB_ENV
            echo "TEST_STATUS=$TEST_STATUS" >> $GITHUB_ENV
            echo "TEST_ID=$TEST_ID" >> $GITHUB_ENV
            
            # Check if execution actually completed
            STEPS_EXECUTED=$(echo "$EXEC_BODY" | jq '.result.steps | length' 2>/dev/null || echo "$EXEC_BODY" | grep -o '"step"' | wc -l || echo "0")
            echo "Steps executed: $STEPS_EXECUTED"
            if [ "$STEPS_EXECUTED" -eq 0 ]; then
              echo "‚ö†Ô∏è WARNING: No steps were executed in the browser."
              echo "This might be due to browser automation issues in Docker environment."
            fi
          elif [ "$EXEC_HTTP_CODE" -eq 404 ]; then
            echo "‚ùå Test not found (404) - Test ID: $TEST_ID"
            echo "Raw execution response: $EXEC_RESPONSE"
            exit 1
          elif [ "$EXEC_HTTP_CODE" -eq 000 ] || [ -z "$EXEC_HTTP_CODE" ]; then
            echo "‚ùå Connection failed or server crashed (HTTP 000 or empty)"
            echo "This usually indicates the server crashed during execution."
            echo "Raw execution response: $EXEC_RESPONSE"
            echo "‚ö†Ô∏è This is expected in Docker environments where browser automation may fail."
            echo "TEST_STATUS=failed" >> $GITHUB_ENV
            echo "TEST_ID=$TEST_ID" >> $GITHUB_ENV
          else
            echo "‚ùå Test execution failed with HTTP $EXEC_HTTP_CODE"
            echo "Raw execution response: $EXEC_RESPONSE"
            # Try to extract error message
            ERROR_MSG=$(echo "$EXEC_BODY" | jq -r '.error // .message // "Unknown error"' 2>/dev/null || echo "Unknown error")
            echo "Error message: $ERROR_MSG"
            exit 1
          fi
        else
          echo "‚ùå Failed to create test"
          echo "Raw create response: $CREATE_RESPONSE"
          exit 1
        fi
        
        # Cleanup
        rm -f /tmp/test-payload.json /tmp/exec-payload.json


    - name: Verify test execution results
      run: |
        echo "üìä Verifying test execution results..."
        if [ -n "${{ env.EXECUTION_ID }}" ]; then
          echo "‚úÖ Test executed in platform successfully!"
          echo "Execution ID: ${{ env.EXECUTION_ID }}"
          echo "Test Status: ${{ env.TEST_STATUS }}"
          echo "Test ID: ${{ env.TEST_ID }}"
          
          # Get detailed execution results
          echo "üìã Getting detailed execution results..."
          DETAILED_RESULTS=$(curl -X GET "${BACKEND_URL:-http://localhost:3001}/api/execution/${{ env.EXECUTION_ID }}/results" | jq '.')
          echo "Detailed Results:"
          echo "$DETAILED_RESULTS" | jq '.'
          
          STEPS_EXECUTED=$(echo "$DETAILED_RESULTS" | jq '.execution.result.steps | length')
          echo "Steps executed: $STEPS_EXECUTED"
          
          if [ "$STEPS_EXECUTED" -gt 0 ]; then
            echo "üéâ SUCCESS: Browser execution completed! Steps were executed."
            echo "Step details:"
            echo "$DETAILED_RESULTS" | jq '.execution.result.steps[] | {step: .step, action: .action, target: .target, status: .status, error: .error}'
          else
            echo "‚ö†Ô∏è WARNING: No steps were executed in the browser."
          fi
        else
          echo "‚ùå No execution ID found - test may not have been executed"
        fi

    - name: Update Slack main thread with test result
      if: env.EXECUTION_ID != '' && env.TEST_ID != '' && env.TEST_STATUS != '' && (env.ENABLE_SLACK == 'true' && (env.SLACK_NOTIFY_ONLY_FAILURES != 'true' || env.TEST_STATUS == 'failed'))
      run: |
        echo "üì¢ Updating Slack main thread with test result..."
        if [ -n "${{ env.EXECUTION_ID }}" ] && [ -n "${{ env.TEST_ID }}" ] && [ -n "${{ env.TEST_STATUS }}" ]; then
          # Additional check for failure-only mode (outer if already ensures Slack is enabled)
          if [ "${{ env.SLACK_NOTIFY_ONLY_FAILURES }}" = "true" ] && [ "${{ env.TEST_STATUS }}" != "failed" ]; then
            echo "‚ÑπÔ∏è Skipping Slack notification (only failures enabled, test status: ${{ env.TEST_STATUS }})"
            exit 0
          fi
          
          echo "üîÑ Calling Slack update API..."
          
          # Prepare the update payload with dataApp name and tenant name (only shown for failed tests)
          UPDATE_PAYLOAD=$(jq -n \
            --arg testName "GitHub Action Test - ${{ github.run_id }}" \
            --arg status "${{ env.TEST_STATUS }}" \
            --arg workflowRunUrl "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}" \
            --arg dataAppName "${{ env.DATAAPP_NAME }}" \
            --arg tenantName "${{ env.TENANT_NAME }}" \
            '{
              testName: $testName,
              status: $status,
              workflowRunUrl: $workflowRunUrl,
              dataAppName: (if $dataAppName == "" then null else $dataAppName end),
              tenantName: (if $tenantName == "" then null else $tenantName end)
            }')
          
          echo "üìã Update payload:"
          echo "$UPDATE_PAYLOAD" | jq '.'
          
          # Call the Slack update endpoint
          SLACK_UPDATE_RESPONSE=$(curl -X POST \
            "${BACKEND_URL:-http://localhost:3001}/api/execution/${{ env.EXECUTION_ID }}/slack-update" \
            -H "Content-Type: application/json" \
            -d "$UPDATE_PAYLOAD" \
            -w "\n%{http_code}" \
            --max-time 30)
          
          SLACK_UPDATE_HTTP_CODE=$(echo "$SLACK_UPDATE_RESPONSE" | tail -n1)
          SLACK_UPDATE_BODY=$(echo "$SLACK_UPDATE_RESPONSE" | sed '$d')
          
          echo "Slack Update HTTP Code: $SLACK_UPDATE_HTTP_CODE"
          echo "Slack Update Response: $SLACK_UPDATE_BODY"
          
          if [ "$SLACK_UPDATE_HTTP_CODE" -eq 200 ]; then
            echo "‚úÖ Slack main thread updated successfully!"
            echo "$SLACK_UPDATE_BODY" | jq '.'
          else
            echo "‚ö†Ô∏è Slack main thread update failed with HTTP $SLACK_UPDATE_HTTP_CODE"
            echo "Response: $SLACK_UPDATE_BODY"
            # Don't fail the workflow if Slack update fails
          fi
        else
          echo "‚ö†Ô∏è Missing required environment variables for Slack update"
          echo "EXECUTION_ID: ${{ env.EXECUTION_ID }}"
          echo "TEST_ID: ${{ env.TEST_ID }}"
          echo "TEST_STATUS: ${{ env.TEST_STATUS }}"
        fi

    - name: Upload test scenarios
      uses: actions/upload-artifact@v4
      with:
        name: test-scenarios-${{ github.run_id }}
        path: test-scenarios/
        retention-days: 30

    - name: Upload test results
      uses: actions/upload-artifact@v4
      with:
        name: test-results-${{ github.run_id }}
        path: backend/test-results/
        retention-days: 30


    - name: Comment on workflow
      run: |
        echo "‚úÖ AI Test Automation Pipeline completed successfully!"
        echo ""
        echo "üìä Pipeline Summary:"
        echo "   ‚Ä¢ Natural language processing: ‚úÖ"
        echo "   ‚Ä¢ Test code generation: ‚úÖ"
        echo "   ‚Ä¢ Test creation in platform: ‚úÖ"
        echo "   ‚Ä¢ Test execution: ‚úÖ"
        echo "   ‚Ä¢ Slack notifications: ‚úÖ"
        echo ""
        echo "üìÅ Files uploaded as artifacts:"
        echo "   - test-scenario-${{ github.run_id }}.md (comprehensive report)"
        echo "   - code-response-${{ github.run_id }}.json (raw code response)"
        echo "   - test-steps-${{ github.run_id }}.txt (human readable steps)"
          echo "   - test-results-${{ github.run_id }} (test execution results)"
          echo "   - generated-test-${{ github.run_id }}.js (executable test file)"
        echo ""
        echo "üéØ Next steps:"
        echo "   1. Download the artifacts from this workflow run"
          echo "   2. ‚úÖ Tests were executed automatically!"
          echo "   3. Check test-results artifact for screenshots/videos"
          echo "   4. Use generated-test-${{ github.run_id }}.js for future runs"
        echo "   5. Check Slack for detailed execution notifications"
        echo ""
        echo "üîó Platform Integration:"
        echo "   ‚Ä¢ Test created in platform with ID: ${{ env.TEST_ID }}"
        echo "   ‚Ä¢ Execution ID: ${{ env.EXECUTION_ID }}"
        echo "   ‚Ä¢ Status: ${{ env.TEST_STATUS }}"