name: Daily AI Test Automation - Jabanas

on:
  # schedule:
  #   - cron: '0 10 * * *'
  workflow_dispatch:
    inputs:
      test_description:
        description: 'Test description in plain English. For supported commands, see: https://rapidcanvas.atlassian.net/wiki/spaces/RAPIDCANVA/pages/887554049/Test+Automation+Platform+-+Supported+Commands+Documentation'
        required: true
        type: string
      slack_channel:
        description: 'Provide slack channel name(Make sure bot - test-automation-platform is added to mentioned slack channel)'
        required: false
        type: string
      slack_channel_id:
        description: 'Provide slack channel ID (e.g., C09F5F2MH8D). You can find this by right-clicking on the channel name in Slack and selecting "Copy link"'
        required: false
        type: string
      headless:
        description: 'Run browser in headless mode (true) or show browser window (false) - GitHub Actions default is headless'
        required: false
        type: boolean
        default: true
      enable_slack:
        description: 'Enable Slack notifications'
        required: false
        type: boolean
        default: true
      slack_notify_only_failures:
        description: 'Send Slack notifications only for failed tests (only applies if enable_slack is true)'
        required: false
        type: boolean
        default: false

env:
  TEST_DESCRIPTION: |
    Open https://app.rapidcanvas.ai/ Enter testAutomation@gmail.com in email Click Next Enter testAutomation03@ in Password Click Sign In Verify Dashboard Open https://app.rapidcanvas.ai/apps/Jabanas%20AI%20Interface/Jabanas_AI?autoLaunch=true Wait 30sec If(text=Relaunch) then Click on Relaunch If(text=Launching) then wait 150sec Wait 100sec Click on High-Level Summary with AI Wait 30sec Verify no error messages or exceptions are displayed on UI with AI Click on Operational Breakdown with AI Wait 30sec Verify no error messages or exceptions are displayed on UI with AI Click on Safety with AI Wait 30sec Verify no error messages or exceptions are displayed on UI with AI Click on Maintenance & Technical Activities with AI Wait 30sec Verify no error messages or exceptions are displayed on UI with AI Click on Data Explorer with AI Wait 30sec Verify no error messages or exceptions are displayed on UI with AI Click on AskAI with AI Wait 80sec Verify no error messages or exceptions are displayed on UI with AI
  OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
  OPENAI_MODEL: gpt-4o-mini
  SLACK_CHANNEL: 'rc-cust-jabanas-internal'
  SLACK_CHANNEL_ID: 'C081S6S3SH3'
  SLACK_BOT_TOKEN: ${{ secrets.SLACK_BOT_TOKEN }}
  SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
  ENABLE_SLACK: true
  SLACK_NOTIFY_ONLY_FAILURES: true
  HEADLESS: true
  SLACK_MENTION: 'U09GWTJPJJF'  # Use Slack user ID (e.g., U1234567890) for proper mentions, or username (e.g., Pablo Souza)
  DATAAPP_NAME: 'Jabanas AI Interface'
  TENANT_NAME: 'Jabanas_AI'

jobs:
  create-test-scenario:
    runs-on: ubuntu-latest
    
    steps:
    - name: üìö Documentation Link
      run: |
        echo "## üìö Test Automation Documentation" >> $GITHUB_STEP_SUMMARY
        echo "**Supported Commands**: [View Documentation](https://rapidcanvas.atlassian.net/wiki/spaces/RAPIDCANVA/pages/887554049/Test+Automation+Platform+-+Supported+Commands+Documentation)" >> $GITHUB_STEP_SUMMARY
        echo "" >> $GITHUB_STEP_SUMMARY
        echo "This documentation contains all supported commands and syntax for writing test descriptions." >> $GITHUB_STEP_SUMMARY

    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'

    - name: Install backend dependencies
      run: |
        cd backend
        npm ci

    - name: Install Playwright browsers
      run: |
        cd backend
        echo "üîç Checking Playwright installation..."
        npx playwright --version
        echo "üöÄ Installing Chromium browser..."
        npx playwright install chromium
        echo "üîß Installing system dependencies..."
        npx playwright install-deps chromium
        echo "‚úÖ Playwright installation completed!"
        echo "üîç Verifying installation..."
        npx playwright install chromium --dry-run

    - name: Build backend
      run: |
        cd backend
        npm run build

    - name: Start backend server
      run: |
        cd backend
        DB_DISABLED=true NODE_ENV=development PORT=3001 SLACK_CHANNEL_ID=${{ env.SLACK_CHANNEL_ID }} npm start &
        echo "Backend server starting..."
        
        # Wait for backend to be ready
        for i in {1..30}; do
          if curl -f http://localhost:3001/health >/dev/null 2>&1; then
            echo "‚úÖ Backend is ready!"
            break
          fi
          echo "Waiting for backend... ($i/30)"
          sleep 2
        done

    - name: Generate and create complete test scenario
      run: |
        echo "üöÄ Generating and creating complete test scenario from: ${{ env.TEST_DESCRIPTION }}"
        echo "Test description length: ${#TEST_DESCRIPTION}"
        
        if [ -z "${{ env.TEST_DESCRIPTION }}" ]; then
          echo "‚ùå No test description provided"
          echo "Raw env value: '${{ env.TEST_DESCRIPTION }}'"
          exit 1
        fi
        
        echo "‚úÖ Test description provided"
        echo "Creating test-scenarios directory..."
        mkdir -p test-scenarios
        echo "Calling API to parse steps..."
        
        # Create properly escaped JSON payload
        # GitHub Actions converts newlines to spaces, so we need to restore them
        # The web interface sends text with actual \n characters, so we need to match that
        echo "üîç Restoring newlines to match web interface format..."
        echo "Original input: ${{ env.TEST_DESCRIPTION }}"
        
        # Convert spaces back to newlines for action keywords (same as web interface)
        # Handle conditional statements as complete lines: "If(text=X) then Action"
        TEST_DESC_WITH_NEWLINES=$(echo "${{ env.TEST_DESCRIPTION }}" | sed 's/ Open https:/\nOpen https:/g' | sed 's/ Enter /\nEnter /g' | sed 's/ Verify /\nVerify /g' | sed 's/ Wait /\nWait /g' | sed 's/ If(/\nIf(/g')
        
        # Handle Click statements - split only standalone Click, not those after "then"
        TEST_DESC_WITH_NEWLINES=$(echo "$TEST_DESC_WITH_NEWLINES" | sed 's/\([^n]\) Click /\1\nClick /g')
        
        echo "Restored description with newlines:"
        echo "$TEST_DESC_WITH_NEWLINES"
        echo ""
        
        jq -n --arg text "$TEST_DESC_WITH_NEWLINES" '{text: $text}' > /tmp/nlp-payload.json
        
        STEPS_RESPONSE=$(curl -X POST ${BACKEND_URL:-http://localhost:3001}/api/nlp/parse -H "Content-Type: application/json" -d @/tmp/nlp-payload.json -w "\n%{http_code}")
        HTTP_CODE=$(echo "$STEPS_RESPONSE" | tail -n1)
        STEPS_BODY=$(echo "$STEPS_RESPONSE" | sed '$d')
        
        echo "Steps HTTP Code: $HTTP_CODE"
        echo "Steps Response Length: ${#STEPS_BODY}"
        echo "Success: $(echo "$STEPS_BODY" | grep -o '"success":true' || echo 'false')"
        
        # Debug: Check number of steps parsed
        STEPS_COUNT=$(echo "$STEPS_BODY" | jq '.steps | length' 2>/dev/null || echo "0")
        echo "Number of steps parsed: $STEPS_COUNT"
        
        if [ "$STEPS_COUNT" -gt 5 ]; then
            echo "‚úÖ SUCCESS: Multiple steps parsed correctly!"
            echo "First few steps:"
            echo "$STEPS_BODY" | jq '.steps[0:3]'
        else
            echo "‚ùå ISSUE: Only $STEPS_COUNT step(s) parsed"
            echo "Full response:"
            echo "$STEPS_BODY" | jq '.'
        fi
        
        if [ "$HTTP_CODE" -eq 200 ] || [ "$HTTP_CODE" -eq 201 ]; then
          echo "‚úÖ Test steps generated successfully!"
          echo "Saving NLP parsing response..."
          echo "$STEPS_BODY" > test-scenarios/steps-response-${{ github.run_id }}.json
          echo "Creating payload..."
          echo "$STEPS_BODY" | jq -c '{steps: .steps, language: "typescript"}' > /tmp/steps.json
          echo "Payload created:"
          cat /tmp/steps.json
          echo ""
          
          echo "Calling API to generate code..."
          CODE_RESPONSE=$(curl -X POST ${BACKEND_URL:-http://localhost:3001}/api/nlp/generate-code -H "Content-Type: application/json" -d @/tmp/steps.json -w "\n%{http_code}")
          CODE_HTTP_CODE=$(echo "$CODE_RESPONSE" | tail -n1)
          CODE_BODY=$(echo "$CODE_RESPONSE" | sed '$d')
          
          echo "Code HTTP Code: $CODE_HTTP_CODE"
          echo "Code Response Length: ${#CODE_BODY}"
          echo "Code Success: $(echo "$CODE_BODY" | grep -o '"success":true' || echo 'false')"
          
          if [ "$CODE_HTTP_CODE" -eq 200 ] || [ "$CODE_HTTP_CODE" -eq 201 ]; then
            echo "‚úÖ Test code generated successfully!"
            echo "Creating test scenario files..."
            mkdir -p test-scenarios
            
            echo "Extracting test steps..."
            TEST_STEPS=$(echo "$STEPS_BODY" | jq -r '.steps // .parsedSteps // "No steps generated"' 2>/dev/null || echo "No steps generated - parsing failed")
            
            echo "Creating comprehensive test scenario file..."
            # Create markdown file using echo commands to avoid YAML issues
            echo "# Test Scenario" > test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "Generated on: $(date -u +%Y-%m-%dT%H:%M:%SZ)" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "Triggered by: ${{ github.actor }}" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "Workflow Run: ${{ github.run_id }}" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "## Test Description" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "${{ env.TEST_DESCRIPTION }}" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "## Generated Test Steps" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "\`\`\`json" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "$STEPS_BODY" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "\`\`\`" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "## Generated Test Code Response" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "\`\`\`json" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "$CODE_BODY" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "\`\`\`" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "## Test Steps (Human Readable)" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "$TEST_STEPS" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "## Usage Instructions" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "1. Extract the code from the JSON response above" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "2. Save it as a .js file in your test project" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            echo "3. Run with: npx playwright test your-test-file.js" >> test-scenarios/test-scenario-${{ github.run_id }}.md
            
            echo "Creating raw response file..."
            echo "$CODE_BODY" > test-scenarios/code-response-${{ github.run_id }}.json
            echo "Creating steps file..."
            echo "$TEST_STEPS" > test-scenarios/test-steps-${{ github.run_id }}.txt
            
            echo "‚úÖ Test scenario files created successfully!"
            echo "Files created:"
            ls -la test-scenarios/
            echo "Main file size:"
            wc -c test-scenarios/test-scenario-${{ github.run_id }}.md
          else
            echo "‚ùå Failed to generate test code"
            echo "Raw code response: $CODE_RESPONSE"
            exit 1
          fi
        else
          echo "‚ùå Failed to generate test steps"
          echo "Raw steps response: $STEPS_RESPONSE"
          echo "Debug: TEST_DESCRIPTION value: '${{ env.TEST_DESCRIPTION }}'"
          echo "Debug: TEST_DESCRIPTION length: ${#TEST_DESCRIPTION}"
          exit 1
        fi
        
        rm -f /tmp/steps.json /tmp/nlp-payload.json

    - name: Create test in platform and execute
      run: |
        echo "üöÄ Creating test in platform and executing..."
        echo "üìù Creating test payload..."
        TEST_NAME="GitHub Action Test - ${{ github.run_id }}"
        
        # Extract steps from the original NLP parsing response (like the frontend does)
        STEPS_DATA=$(cat test-scenarios/steps-response-${{ github.run_id }}.json | jq -c '.steps // []')
        
        echo "üîç Extracted steps data:"
        echo "$STEPS_DATA" | jq '.'
        echo ""
        
        # Prepare slack notify only failures flag
        if [ "${{ env.SLACK_NOTIFY_ONLY_FAILURES }}" = "true" ]; then
          SLACK_NOTIFY_ONLY_FAILURES_VALUE="true"
        else
          SLACK_NOTIFY_ONLY_FAILURES_VALUE="false"
        fi
        
        # Create test payload using jq to properly escape JSON (matching frontend behavior)
        jq -n \
          --arg name "$TEST_NAME" \
          --arg description "${{ env.TEST_DESCRIPTION }}" \
          --argjson steps "$STEPS_DATA" \
          --arg workflowRunUrl "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}" \
          --argjson slackNotifyOnlyFailures "$SLACK_NOTIFY_ONLY_FAILURES_VALUE" \
          --arg slackMention "U08HRLKPTKJ" \
          '{
            name: $name,
            description: $description,
            steps: $steps,
            workflowRunUrl: $workflowRunUrl,
            slackNotifyOnlyFailures: $slackNotifyOnlyFailures,
            slackMention: $slackMention
          }' > /tmp/test-payload.json
        
        echo "Creating test in platform..."
        CREATE_RESPONSE=$(curl -X POST ${BACKEND_URL:-http://localhost:3001}/api/tests -H "Content-Type: application/json" -d @/tmp/test-payload.json -w "\n%{http_code}")
        CREATE_HTTP_CODE=$(echo "$CREATE_RESPONSE" | tail -n1)
        CREATE_BODY=$(echo "$CREATE_RESPONSE" | sed '$d')
        echo "Create Test HTTP Code: $CREATE_HTTP_CODE"
        
        if [ "$CREATE_HTTP_CODE" -eq 201 ]; then
          echo "‚úÖ Test created successfully!"
            TEST_ID=$(echo "$CREATE_BODY" | jq -r '.test.id // "unknown"')
            echo "Test ID: $TEST_ID"
            echo "üîç Debug: Full create response:"
            echo "$CREATE_BODY" | jq '.'
          echo "üöÄ Executing test..."
          
          # Set browser execution mode for GitHub Actions
          # GitHub Actions default is headless: true (no GUI available)
          if [ "${{ env.HEADLESS }}" = "true" ]; then
            HEADLESS_VALUE="true"
            echo "üñ•Ô∏è Running in HEADLESS mode (GitHub Actions - no GUI available)"
          else
            HEADLESS_VALUE="false"
            echo "üñ•Ô∏è Running in HEADED mode (browser window visible) - not recommended for GitHub Actions"
          fi
          
          if [ "${{ env.ENABLE_SLACK }}" = "true" ]; then
            SLACK_VALUE="true"
          else
            SLACK_VALUE="false"
          fi
          
          if [ "${{ env.SLACK_NOTIFY_ONLY_FAILURES }}" = "true" ]; then
            SLACK_NOTIFY_ONLY_FAILURES_VALUE="true"
          else
            SLACK_NOTIFY_ONLY_FAILURES_VALUE="false"
          fi
          
          # Match web interface execution parameters exactly
          jq -n \
            --argjson headless "$HEADLESS_VALUE" \
            --argjson enableSlack "$SLACK_VALUE" \
            --argjson slackNotifyOnlyFailures "$SLACK_NOTIFY_ONLY_FAILURES_VALUE" \
            '{
              headless: $headless,
              slowMoMs: 1000,
              enableSlackNotifications: $enableSlack,
              slackNotifyOnlyFailures: $slackNotifyOnlyFailures
            }' > /tmp/exec-payload.json
          
          echo "üìã Execution payload:"
          cat /tmp/exec-payload.json
          echo ""
          
          echo "üîç Testing execution with test ID: $TEST_ID"
          echo "üîç Checking if test exists first..."
          curl -X GET ${BACKEND_URL:-http://localhost:3001}/api/tests/$TEST_ID | jq '.test.id // "not found"'
          
          echo "üîç Debug: Checking Playwright installation in backend..."
          curl -X GET ${BACKEND_URL:-http://localhost:3001}/health | jq '.' || echo "Health check failed"
          
          echo "üöÄ Executing test..."
          # Increased timeout to 45 minutes (2700 seconds) to accommodate tests with multiple long waits
          EXEC_RESPONSE=$(curl -X POST ${BACKEND_URL:-http://localhost:3001}/api/execution/$TEST_ID/run -H "Content-Type: application/json" -d @/tmp/exec-payload.json -w "\n%{http_code}" --max-time 2700)
          EXEC_HTTP_CODE=$(echo "$EXEC_RESPONSE" | tail -n1)
          EXEC_BODY=$(echo "$EXEC_RESPONSE" | sed '$d')
          echo "Execution HTTP Code: $EXEC_HTTP_CODE"
          echo "Execution Response: $EXEC_BODY"
          
          if [ "$EXEC_HTTP_CODE" -eq 200 ]; then
            echo "‚úÖ Test executed successfully!"
            echo "Execution Result:"
            echo "$EXEC_BODY" | jq '.'
            EXECUTION_ID=$(echo "$EXEC_BODY" | jq -r '.executionId // "unknown"')
            TEST_STATUS=$(echo "$EXEC_BODY" | jq -r '.status // "unknown"')
            echo "EXECUTION_ID=$EXECUTION_ID" >> $GITHUB_ENV
            echo "TEST_STATUS=$TEST_STATUS" >> $GITHUB_ENV
            echo "TEST_ID=$TEST_ID" >> $GITHUB_ENV
            
            # Check if execution actually completed
            STEPS_EXECUTED=$(echo "$EXEC_BODY" | jq '.result.steps | length' 2>/dev/null || echo "0")
            echo "Steps executed: $STEPS_EXECUTED"
            if [ "$STEPS_EXECUTED" -eq 0 ]; then
              echo "‚ö†Ô∏è WARNING: No steps were executed in the browser."
              echo "This might be due to browser automation issues in Docker environment."
            fi
          elif [ "$EXEC_HTTP_CODE" -eq 404 ]; then
            echo "‚ùå Test not found (404) - Test ID: $TEST_ID"
            echo "Raw execution response: $EXEC_RESPONSE"
            exit 1
          else
            echo "‚ùå Test execution failed with HTTP $EXEC_HTTP_CODE"
            echo "Raw execution response: $EXEC_RESPONSE"
            exit 1
          fi
        else
          echo "‚ùå Failed to create test"
          echo "Raw create response: $CREATE_RESPONSE"
          exit 1
        fi
        
        # Cleanup
        rm -f /tmp/test-payload.json /tmp/exec-payload.json


    - name: Verify test execution results
      run: |
        echo "üìä Verifying test execution results..."
        if [ -n "${{ env.EXECUTION_ID }}" ]; then
          echo "‚úÖ Test executed in platform successfully!"
          echo "Execution ID: ${{ env.EXECUTION_ID }}"
          echo "Test Status: ${{ env.TEST_STATUS }}"
          echo "Test ID: ${{ env.TEST_ID }}"
          
          # Get detailed execution results
          echo "üìã Getting detailed execution results..."
          DETAILED_RESULTS=$(curl -X GET "${BACKEND_URL:-http://localhost:3001}/api/execution/${{ env.EXECUTION_ID }}/results" | jq '.')
          echo "Detailed Results:"
          echo "$DETAILED_RESULTS" | jq '.'
          
          STEPS_EXECUTED=$(echo "$DETAILED_RESULTS" | jq '.execution.result.steps | length')
          echo "Steps executed: $STEPS_EXECUTED"
          
          if [ "$STEPS_EXECUTED" -gt 0 ]; then
            echo "üéâ SUCCESS: Browser execution completed! Steps were executed."
            echo "Step details:"
            echo "$DETAILED_RESULTS" | jq '.execution.result.steps[] | {step: .step, action: .action, target: .target, status: .status, error: .error}'
          else
            echo "‚ö†Ô∏è WARNING: No steps were executed in the browser."
          fi
        else
          echo "‚ùå No execution ID found - test may not have been executed"
        fi

    - name: Update Slack main thread with test result
      if: env.EXECUTION_ID != '' && env.TEST_ID != '' && env.TEST_STATUS != '' && (env.ENABLE_SLACK == 'true' && (env.SLACK_NOTIFY_ONLY_FAILURES != 'true' || env.TEST_STATUS == 'failed'))
      run: |
        echo "üì¢ Updating Slack main thread with test result..."
        if [ -n "${{ env.EXECUTION_ID }}" ] && [ -n "${{ env.TEST_ID }}" ] && [ -n "${{ env.TEST_STATUS }}" ]; then
          # Additional check for failure-only mode (outer if already ensures Slack is enabled)
          if [ "${{ env.SLACK_NOTIFY_ONLY_FAILURES }}" = "true" ] && [ "${{ env.TEST_STATUS }}" != "failed" ]; then
            echo "‚ÑπÔ∏è Skipping Slack notification (only failures enabled, test status: ${{ env.TEST_STATUS }})"
            exit 0
          fi
          
          echo "üîÑ Calling Slack update API..."
          
          # Prepare the update payload with dataApp name and tenant name (only shown for failed tests)
          UPDATE_PAYLOAD=$(jq -n \
            --arg testName "GitHub Action Test - ${{ github.run_id }}" \
            --arg status "${{ env.TEST_STATUS }}" \
            --arg workflowRunUrl "${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}" \
            --arg dataAppName "${{ env.DATAAPP_NAME }}" \
            --arg tenantName "${{ env.TENANT_NAME }}" \
            '{
              testName: $testName,
              status: $status,
              workflowRunUrl: $workflowRunUrl,
              dataAppName: (if $dataAppName == "" then null else $dataAppName end),
              tenantName: (if $tenantName == "" then null else $tenantName end)
            }')
          
          echo "üìã Update payload:"
          echo "$UPDATE_PAYLOAD" | jq '.'
          
          # Call the Slack update endpoint
          SLACK_UPDATE_RESPONSE=$(curl -X POST \
            "${BACKEND_URL:-http://localhost:3001}/api/execution/${{ env.EXECUTION_ID }}/slack-update" \
            -H "Content-Type: application/json" \
            -d "$UPDATE_PAYLOAD" \
            -w "\n%{http_code}" \
            --max-time 30)
          
          SLACK_UPDATE_HTTP_CODE=$(echo "$SLACK_UPDATE_RESPONSE" | tail -n1)
          SLACK_UPDATE_BODY=$(echo "$SLACK_UPDATE_RESPONSE" | sed '$d')
          
          echo "Slack Update HTTP Code: $SLACK_UPDATE_HTTP_CODE"
          echo "Slack Update Response: $SLACK_UPDATE_BODY"
          
          if [ "$SLACK_UPDATE_HTTP_CODE" -eq 200 ]; then
            echo "‚úÖ Slack main thread updated successfully!"
            echo "$SLACK_UPDATE_BODY" | jq '.'
          else
            echo "‚ö†Ô∏è Slack main thread update failed with HTTP $SLACK_UPDATE_HTTP_CODE"
            echo "Response: $SLACK_UPDATE_BODY"
            # Don't fail the workflow if Slack update fails
          fi
        else
          echo "‚ö†Ô∏è Missing required environment variables for Slack update"
          echo "EXECUTION_ID: ${{ env.EXECUTION_ID }}"
          echo "TEST_ID: ${{ env.TEST_ID }}"
          echo "TEST_STATUS: ${{ env.TEST_STATUS }}"
        fi

    - name: Upload test scenarios
      uses: actions/upload-artifact@v4
      with:
        name: test-scenarios-${{ github.run_id }}
        path: test-scenarios/
        retention-days: 30

    - name: Upload test results
      uses: actions/upload-artifact@v4
      with:
        name: test-results-${{ github.run_id }}
        path: backend/test-results/
        retention-days: 30


    - name: Comment on workflow
      run: |
        echo "‚úÖ AI Test Automation Pipeline completed successfully!"
        echo ""
        echo "üìä Pipeline Summary:"
        echo "   ‚Ä¢ Natural language processing: ‚úÖ"
        echo "   ‚Ä¢ Test code generation: ‚úÖ"
        echo "   ‚Ä¢ Test creation in platform: ‚úÖ"
        echo "   ‚Ä¢ Test execution: ‚úÖ"
        echo "   ‚Ä¢ Slack notifications: ‚úÖ"
        echo ""
        echo "üìÅ Files uploaded as artifacts:"
        echo "   - test-scenario-${{ github.run_id }}.md (comprehensive report)"
        echo "   - code-response-${{ github.run_id }}.json (raw code response)"
        echo "   - test-steps-${{ github.run_id }}.txt (human readable steps)"
          echo "   - test-results-${{ github.run_id }} (test execution results)"
          echo "   - generated-test-${{ github.run_id }}.js (executable test file)"
        echo ""
        echo "üéØ Next steps:"
        echo "   1. Download the artifacts from this workflow run"
          echo "   2. ‚úÖ Tests were executed automatically!"
          echo "   3. Check test-results artifact for screenshots/videos"
          echo "   4. Use generated-test-${{ github.run_id }}.js for future runs"
        echo "   5. Check Slack for detailed execution notifications"
        echo ""
        echo "üîó Platform Integration:"
        echo "   ‚Ä¢ Test created in platform with ID: ${{ env.TEST_ID }}"
        echo "   ‚Ä¢ Execution ID: ${{ env.EXECUTION_ID }}"
        echo "   ‚Ä¢ Status: ${{ env.TEST_STATUS }}"