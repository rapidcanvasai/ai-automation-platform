name: "Daily Graph Monitoring - Template"

# TEMPLATE: Graph-based deterministic DataApp monitoring.
#
# Two-phase approach:
#   Phase 1 (Discovery): Crawl the DataApp to build a navigation graph of all
#     pages, links, and buttons. Run once or whenever the app changes.
#   Phase 2 (Monitoring): Traverse the saved graph, check every page loads,
#     verify every link works, and detect structural regressions.
#
# This is MORE RELIABLE than LLM-driven monitoring because:
#   - Deterministic: same graph → same checks every run
#   - No LLM dependency: monitoring doesn't need OpenAI API
#   - Regression detection: compares current state with saved graph
#   - Full coverage: every page and link is verified, not just what the LLM explores
#
# Discovery runs periodically (weekly) or on-demand.
# Monitoring runs daily.

on:
  schedule:
    # Daily monitoring at 09:00 UTC
    - cron: '0 9 * * *'
  workflow_dispatch:
    inputs:
      mode:
        description: 'discover = build graph, monitor = check health'
        required: true
        type: choice
        options:
          - monitor
          - discover
        default: monitor
      app_name:
        description: 'Override app name'
        required: false
        type: string

# ─── CUSTOMIZE THIS SECTION FOR YOUR DATAAPP ────────────────────────────────
env:
  # Unique app name (used to save/load graph)
  APP_NAME: "your-dataapp-name"

  # Entry point URLs (comma-separated, used during discovery)
  ENTRY_POINTS: "https://app.rapidcanvas.ai/apps/YOUR_APP/YOUR_TENANT"

  # App type: react, streamlit, or unknown (auto-detect)
  APP_TYPE: "unknown"

  # Discovery settings
  MAX_DEPTH: 4
  MAX_NODES: 50

  # Monitoring settings
  CHECK_EDGES: true
  LOAD_TIME_THRESHOLD_MS: 10000

  # Slack configuration
  SLACK_CHANNEL: 'your-slack-channel'
  SLACK_CHANNEL_ID: 'YOUR_CHANNEL_ID'
  ENABLE_SLACK: true
  SLACK_NOTIFY_ONLY_FAILURES: true

  # Metadata
  DATAAPP_NAME: 'Your DataApp Name'
  TENANT_NAME: 'Your Tenant Name'
# ─────────────────────────────────────────────────────────────────────────────

jobs:
  graph-monitor:
    runs-on: ubuntu-latest
    timeout-minutes: 20

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Setup Node.js
      uses: actions/setup-node@v4
      with:
        node-version: '18'

    - name: Install backend dependencies
      run: |
        cd backend
        npm ci

    - name: Install Playwright browsers
      run: |
        cd backend
        npx playwright install chromium
        npx playwright install-deps chromium

    - name: Build backend
      run: |
        cd backend
        npm run build

    - name: Restore saved graph
      if: inputs.mode != 'discover'
      uses: actions/cache/restore@v4
      with:
        path: backend/test-results/site-graphs/
        key: graph-${{ env.APP_NAME }}-
        restore-keys: |
          graph-${{ env.APP_NAME }}-

    - name: Start backend server
      env:
        OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
        SLACK_CHANNEL_ID: ${{ env.SLACK_CHANNEL_ID }}
        SLACK_BOT_TOKEN: ${{ secrets.SLACK_BOT_TOKEN }}
        SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
      run: |
        cd backend
        DB_DISABLED=true NODE_ENV=development PORT=3001 npm start &

        for i in {1..30}; do
          if curl -f http://localhost:3001/health >/dev/null 2>&1; then
            echo "Backend is ready!"
            break
          fi
          echo "Waiting for backend... ($i/30)"
          sleep 2
        done

    - name: Run Graph Discovery
      if: inputs.mode == 'discover'
      env:
        MONITOR_EMAIL: ${{ secrets.MONITOR_EMAIL }}
        MONITOR_PASSWORD: ${{ secrets.MONITOR_PASSWORD }}
      run: |
        echo "=== Graph Discovery ==="
        echo "App: $APP_NAME"
        echo "Entry Points: $ENTRY_POINTS"
        echo ""

        # Convert comma-separated entry points to JSON array
        ENTRY_JSON=$(echo "$ENTRY_POINTS" | python3 -c "
        import sys, json
        eps = [e.strip() for e in sys.stdin.read().strip().split(',') if e.strip()]
        print(json.dumps(eps))
        ")

        # Build payload
        jq -n \
          --arg appName "${{ inputs.app_name || env.APP_NAME }}" \
          --argjson entryPoints "$ENTRY_JSON" \
          --arg appType "$APP_TYPE" \
          --arg email "$MONITOR_EMAIL" \
          --arg password "$MONITOR_PASSWORD" \
          --argjson maxDepth "${MAX_DEPTH:-4}" \
          --argjson maxNodes "${MAX_NODES:-50}" \
          --argjson enableSlack "${ENABLE_SLACK:-true}" \
          '{
            appName: $appName,
            entryPoints: $entryPoints,
            appType: $appType,
            loginCredentials: { email: $email, password: $password },
            maxDepth: $maxDepth,
            maxNodes: $maxNodes,
            headless: true,
            slowMoMs: 300,
            enableSlackNotifications: $enableSlack
          }' > /tmp/discovery-payload.json

        echo "Payload (credentials hidden):"
        cat /tmp/discovery-payload.json | jq 'del(.loginCredentials)'
        echo ""

        RESPONSE=$(curl -s -X POST \
          http://localhost:3001/api/ai/graph/discover \
          -H "Content-Type: application/json" \
          -d @/tmp/discovery-payload.json)

        DISCOVERY_ID=$(echo "$RESPONSE" | jq -r '.discoveryId // "unknown"')
        echo "Discovery ID: $DISCOVERY_ID"

        # Poll for completion
        echo "Waiting for discovery to complete..."
        POLL_TIMEOUT=600
        POLL_INTERVAL=10
        ELAPSED=0
        COMPLETED=false

        while [ "$ELAPSED" -lt "$POLL_TIMEOUT" ]; do
          sleep $POLL_INTERVAL
          ELAPSED=$((ELAPSED + POLL_INTERVAL))

          STREAM_DATA=$(curl -s -N --max-time 3 "http://localhost:3001/api/ai/stream/$DISCOVERY_ID" 2>/dev/null || true)

          if echo "$STREAM_DATA" | grep -q '"type":"graph:discovery:complete"'; then
            echo "Discovery completed!"
            COMPLETED=true
            REPORT=$(echo "$STREAM_DATA" | grep '"type":"graph:discovery:complete"' | tail -1 | sed 's/^data: //')
            echo "$REPORT" > /tmp/discovery-report.json
            break
          fi

          if echo "$STREAM_DATA" | grep -q '"type":"graph:discovery:error"'; then
            echo "Discovery error!"
            COMPLETED=true
            break
          fi

          echo "Running... ($ELAPSED/$POLL_TIMEOUT s)"
        done

        echo ""
        echo "=== DISCOVERY REPORT ==="
        cat /tmp/discovery-report.json | jq '.' 2>/dev/null || echo "No report"

        rm -f /tmp/discovery-payload.json

    - name: Run Graph Monitoring
      if: inputs.mode != 'discover'
      env:
        MONITOR_EMAIL: ${{ secrets.MONITOR_EMAIL }}
        MONITOR_PASSWORD: ${{ secrets.MONITOR_PASSWORD }}
      run: |
        echo "=== Graph Monitoring ==="
        echo "App: $APP_NAME"
        echo ""

        # Build payload
        jq -n \
          --arg appName "${{ inputs.app_name || env.APP_NAME }}" \
          --arg email "$MONITOR_EMAIL" \
          --arg password "$MONITOR_PASSWORD" \
          --argjson checkEdges "${CHECK_EDGES:-true}" \
          --argjson loadTimeThresholdMs "${LOAD_TIME_THRESHOLD_MS:-10000}" \
          --argjson enableSlack "${ENABLE_SLACK:-true}" \
          '{
            appName: $appName,
            loginCredentials: { email: $email, password: $password },
            checkEdges: $checkEdges,
            loadTimeThresholdMs: $loadTimeThresholdMs,
            headless: true,
            slowMoMs: 200,
            timeoutMs: 300000,
            enableSlackNotifications: $enableSlack
          }' > /tmp/monitor-payload.json

        echo "Payload (credentials hidden):"
        cat /tmp/monitor-payload.json | jq 'del(.loginCredentials)'
        echo ""

        RESPONSE=$(curl -s -X POST \
          http://localhost:3001/api/ai/graph/monitor \
          -H "Content-Type: application/json" \
          -d @/tmp/monitor-payload.json)

        MONITORING_ID=$(echo "$RESPONSE" | jq -r '.monitoringId // "unknown"')
        echo "Monitoring ID: $MONITORING_ID"
        echo "MONITORING_ID=$MONITORING_ID" >> $GITHUB_ENV

        # Poll for completion
        echo "Waiting for monitoring to complete..."
        POLL_TIMEOUT=600
        POLL_INTERVAL=10
        ELAPSED=0
        COMPLETED=false

        while [ "$ELAPSED" -lt "$POLL_TIMEOUT" ]; do
          sleep $POLL_INTERVAL
          ELAPSED=$((ELAPSED + POLL_INTERVAL))

          STREAM_DATA=$(curl -s -N --max-time 3 "http://localhost:3001/api/ai/stream/$MONITORING_ID" 2>/dev/null || true)

          if echo "$STREAM_DATA" | grep -q '"type":"graph:monitor:complete"'; then
            echo "Monitoring completed!"
            COMPLETED=true
            REPORT=$(echo "$STREAM_DATA" | grep '"type":"graph:monitor:complete"' | tail -1 | sed 's/^data: //')
            echo "$REPORT" > /tmp/monitoring-report.json
            break
          fi

          if echo "$STREAM_DATA" | grep -q '"type":"graph:monitor:error"'; then
            echo "Monitoring error!"
            COMPLETED=true
            ERROR_DATA=$(echo "$STREAM_DATA" | grep '"type":"graph:monitor:error"' | tail -1 | sed 's/^data: //')
            echo "$ERROR_DATA" > /tmp/monitoring-report.json
            break
          fi

          echo "Running... ($ELAPSED/$POLL_TIMEOUT s)"
        done

        if [ "$COMPLETED" = "false" ]; then
          echo "Monitoring timed out"
          echo '{"status":"error","error":"timeout"}' > /tmp/monitoring-report.json
        fi

        echo ""
        echo "=== MONITORING REPORT ==="
        cat /tmp/monitoring-report.json | jq '.' 2>/dev/null || cat /tmp/monitoring-report.json

        MONITOR_STATUS=$(cat /tmp/monitoring-report.json | jq -r '.report.status // .status // "unknown"' 2>/dev/null)
        echo "MONITOR_STATUS=$MONITOR_STATUS" >> $GITHUB_ENV

        rm -f /tmp/monitor-payload.json

    - name: Evaluate result
      if: inputs.mode != 'discover'
      run: |
        echo "## Graph Monitoring Report" >> $GITHUB_STEP_SUMMARY
        echo "- **App**: ${{ env.DATAAPP_NAME }} (${{ env.TENANT_NAME }})" >> $GITHUB_STEP_SUMMARY
        echo "- **Status**: ${{ env.MONITOR_STATUS }}" >> $GITHUB_STEP_SUMMARY

        if [ -f /tmp/monitoring-report.json ]; then
          SUMMARY=$(cat /tmp/monitoring-report.json | jq -r '.report.summary // "No summary"' 2>/dev/null)
          STATS=$(cat /tmp/monitoring-report.json | jq -r '.report.stats // {}' 2>/dev/null)
          REGRESSIONS=$(cat /tmp/monitoring-report.json | jq -r '.report.stats.totalRegressions // 0' 2>/dev/null)

          echo "- **Summary**: $SUMMARY" >> $GITHUB_STEP_SUMMARY
          echo "- **Regressions**: $REGRESSIONS" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo '```json' >> $GITHUB_STEP_SUMMARY
          echo "$STATS" >> $GITHUB_STEP_SUMMARY
          echo '```' >> $GITHUB_STEP_SUMMARY
        fi

        if [ "${{ env.MONITOR_STATUS }}" = "healthy" ]; then
          echo "Application is HEALTHY"
        elif [ "${{ env.MONITOR_STATUS }}" = "degraded" ]; then
          echo "Application is DEGRADED"
        elif [ "${{ env.MONITOR_STATUS }}" = "unhealthy" ] || [ "${{ env.MONITOR_STATUS }}" = "error" ]; then
          echo "Application is UNHEALTHY or ERROR"
          exit 1
        fi

    - name: Save graph to cache
      if: inputs.mode == 'discover'
      uses: actions/cache/save@v4
      with:
        path: backend/test-results/site-graphs/
        key: graph-${{ env.APP_NAME }}-${{ github.run_id }}

    - name: Upload artifacts
      if: always()
      uses: actions/upload-artifact@v4
      with:
        name: graph-monitoring-${{ env.APP_NAME }}-${{ github.run_id }}
        path: |
          backend/test-results/
          /tmp/monitoring-report.json
          /tmp/discovery-report.json
        retention-days: 30
